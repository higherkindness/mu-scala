// When the user clicks on the search box, we want to toggle the search dropdown
function displayToggleSearch(e) {
  e.preventDefault();
  e.stopPropagation();

  closeDropdownSearch(e);
  
  if (idx === null) {
    console.log("Building search index...");
    prepareIdxAndDocMap();
    console.log("Search index built.");
  }
  const dropdown = document.querySelector("#search-dropdown-content");
  if (dropdown) {
    if (!dropdown.classList.contains("show")) {
      dropdown.classList.add("show");
    }
    document.addEventListener("click", closeDropdownSearch);
    document.addEventListener("keydown", searchOnKeyDown);
    document.addEventListener("keyup", searchOnKeyUp);
  }
}

//We want to prepare the index only after clicking the search bar
var idx = null
const docMap = new Map()

function prepareIdxAndDocMap() {
  const docs = [  
    {
      "title": "Accessing metadata on services",
      "url": "/mu-scala/guides/accessing-metadata",
      "content": "Context on services Mu provides a way to create contexts available in the client and server. Specifically, it offers the following features. Client For every RPC call, you need to create an initial context that will be passed to the client The client will have the ability to operate and transform that context, which will be sent to the server in the headers. Server The server will have the ability to extract the context information from the request headers and use them. How to use Let’s assume the following service definition: case class HelloRequest(name: String) case class HelloResponse(greeting: String, happy: Boolean) trait Greeter[F[_]] { def SayHello(req: HelloRequest): F[HelloResponse] } Let’s look at enabling the context on the client-side first. Client side Ordinarily, if you don’t want to use this feature, you would create a cats-effect Resource of an RPC client using the auto-generated Greeter.client method: import mu.examples.protobuf.greeter.* import cats.effect.* import higherkindness.mu.rpc.{ChannelFor, ChannelForAddress} object OrdinaryClientApp extends IOApp { val channelFor: ChannelFor = ChannelForAddress(\"localhost\", 8080) val clientRes: Resource[IO, Greeter[IO]] = Greeter.client[IO](channelFor) def run(args: List[String]): IO[ExitCode] = clientRes.use { client =&gt; for { resp &lt;- client.SayHello(HelloRequest(\"Chris\")) _ &lt;- IO(println(s\"Response: $resp\")) } yield (ExitCode.Success) } } To obtain a client with the context available, use Greeter.contextClient[F, C] instead of Greeter.client. This returns a Greeter[Kleisli[F, C, *]], i.e. a client which takes an arbitrary C as input and returns a response inside the F effect. This method requires a given instance in scope, specifically a ClientContext[F, C]: import cats.effect.Resource import io.grpc.{CallOptions, Channel, Metadata, MethodDescriptor} final case class ClientContextMetaData[C](context: C, metadata: Metadata) trait ClientContext[F[_], C] { def apply[Req, Res]( descriptor: MethodDescriptor[Req, Res], channel: Channel, options: CallOptions, current: C ): Resource[F, ClientContextMetaData[C]] } A ClientContext is an algebra that will take different information from the current call and the initial context (current) and generates a transformed context and an io.grpc.Metadata. The metadata is the information that will travel through the wire in the requests. There’s a helper method in the companion object for generating a ClientContext instance from a function: def impl[F[_], C](f: (C, Metadata) =&gt; F[Unit]): ClientContext[F, C] For example, suppose we want to pass a ‘tag’ via the metadata: import cats.data.Kleisli import io.grpc.Metadata import higherkindness.mu.rpc.internal.context.ClientContext object TaggingClientApp extends IOApp { val channelFor: ChannelFor = ChannelForAddress(\"localhost\", 8080) val key: Metadata.Key[String] = Metadata.Key.of(\"key\", Metadata.ASCII_STRING_MARSHALLER) given ClientContext[IO, String] = ClientContext.impl[IO, String]((tag, md) =&gt; IO(md.put(key, tag))) val clientRes: Resource[IO, Greeter[Kleisli[IO, String, *]]] = Greeter.contextClient[IO, String](channelFor) def run(args: List[String]): IO[ExitCode] = clientRes.use { client =&gt; val kleisli = client.SayHello(HelloRequest(\"Chris\")) for { resp &lt;- kleisli.run(\"my-tag\") _ &lt;- IO(println(s\"Response: $resp\")) } yield (ExitCode.Success) } } Server side For the server, as usual, we need an implementation of the service (shown below): import cats.Applicative import cats.syntax.applicative.* class MyAmazingGreeter[F[_]: Applicative] extends Greeter[F] { def SayHello(req: HelloRequest): F[HelloResponse] = HelloResponse(s\"Hello, ${req.name}!\", happy = true).pure[F] } In general, if you were not using context, you would need to create a gRPC service definition using the auto-generated Greeter.bindService method, specifying your effect monad of choice: import cats.effect.{IO, IOApp, ExitCode} import higherkindness.mu.rpc.server.{GrpcServer, AddService} object OrdinaryServer extends IOApp { given service: Greeter[IO] = new MyAmazingGreeter[IO] def run(args: List[String]): IO[ExitCode] = (for { serviceDef &lt;- Greeter.bindService[IO] _ &lt;- GrpcServer.defaultServer[IO](8080, List(AddService(serviceDef))) } yield ()).useForever } To use the same service with context enabled, you need to call the Greeter.bindContextService method instead. bindContextService[F[_], C] differs from bindService[F[_]] in two ways, which we will explain below. It takes a Greeter as an implicit argument, but instead of a Greeter[F] it requires a Greeter[Kleisli[F, C, *]]. It expects an implicit instance of ServerContext[F, C] in the scope. A ServerContext[F, C] is an algebra that specifies how to build a context of type C from the metadata. import cats.effect.* import io.grpc.{Metadata, MethodDescriptor} trait ServerContext[F[_], C] { def apply[Req, Res]( descriptor: MethodDescriptor[Req, Res], metadata: Metadata ): Resource[F, C] } Like in the case of the client, we have a helper method in the companion object that makes it easier to build instances of ServerContext: def impl[F[_], C](f: Metadata =&gt; F[C]): ServerContext[F, C] Then, to get access to the context in the service, we can implement the service using the Kleisli as the F-type: import cats.Applicative import cats.syntax.applicative.* class MyAmazingContextGreeter[F[_]: Applicative] extends Greeter[Kleisli[F, String, *]] { def SayHello(req: HelloRequest): Kleisli[F, String, HelloResponse] = Kleisli { tag =&gt; // You can use `tag` here HelloResponse(s\"Hello, ${req.name}! You sent me tag '$tag'\", happy = true).pure[F] } } Using bindContextService Putting all this together, your server setup code will look something like this: import cats.data.Kleisli import higherkindness.mu.rpc.internal.context.ServerContext import io.grpc.Metadata object TaggingServer extends IOApp { given Greeter[Kleisli[IO, String, *]] = new MyAmazingContextGreeter[IO] val key: Metadata.Key[String] = Metadata.Key.of(\"key\", Metadata.ASCII_STRING_MARSHALLER) given ServerContext[IO, String] = ServerContext.impl[IO, String](md =&gt; IO(md.get(key))) def run(args: List[String]): IO[ExitCode] = (for { serviceDef &lt;- Greeter.bindContextService[IO, String] _ &lt;- GrpcServer.defaultServer[IO](8080, List(AddService(serviceDef))) } yield ()).useForever }"
    } ,    
    {
      "title": "Schema Evolution - Avro",
      "url": "/mu-scala/reference/schema-evolution/avro",
      "content": "Avro - Schema Evolution From now on, consider that we are using AvroWithSchema as the serialization mechanism in your Mu program. According to the Avro Specs: A reader of Avro data, whether from an RPC or a file, can always parse that data because its schema is provided. But that schema may not be exactly the schema that was expected. For example, if the data was written with a different version of the software than it is read, then records may have had fields added or removed. This page explains how such schema differences should be resolved to preserve compatibility. We’ll try to summarise all the possible cases in both ends: request and response. However, you could go deeper by using this repo where you can play with all of the possibilities. All the cases below assume we are changing the schema used on the server side first, so there are clients using the previous version of the schema while the server uses the new schema. Cases Modifying the Request (Client side) A: Adding a new non-optional field B: Adding a new optional field C: Adding new item to a union D: Removing item from a union E: Replacing item in a union F: Changing the type of an existing field G: Renaming a field H: Removing a field Modifying the Response (Server side) I: Adding a new non-optional field J: Adding a new optional field K: Adding a new item to a union L: Removing item from a union M: Replacing item from a union N: Changing the type of an existing field O: Renaming a field P: Removing a field Modifying the Request A: Adding a new non-optional field You need to specify a default value for the new field, because clients using the old schema will not include the new field in their requests. Before: record Request { string a; int b; } After: record Request { string a; int b; boolean c = true; } B: Adding a new optional field This is a special case of the previous scenario. null should be used as the default value. Before: record Request { string a; int b; } After: record Request { string a; int b; union {null, boolean} c = null; } C: Adding new item to a union This change is safe. Older clients will only send an int or a string, while newer clients might send a boolean. Before: record Request { union {int, string} a; } After: record Request { union {int, string, boolean} a; } D: Removing item from a union This change is NOT safe: older clients might send a string, and the server will not know how to handle it. The only safe choice is to add a new field with a default value. Older clients will send only the old field, while newer clients should send the same value for both the old and new fields. The server side will need to implement logic to handle this situation. Before: record Request { union {int, string, boolean} a; } After: record Request { union {int, string, boolean} a; union {int, boolean} b = 0; } E: Replacing item in a union This is also an incompatible change. If the type is replaced, it will work while the provided value is one of the types in common between the previous union and the new one. Before: record Request { union {int, string} a; } After: record Request { union {int, boolean} a; } It will work if the request is: Request(a = 10) And it will fail if the request is: Request(a = \"Hi\") Again, the safest strategy is to leave the existing field untouched and add a new field. F: Changing the type of an existing field Changing the type of a field is an incompatible change, except in a few special cases. So you need to add a new field with a default value. Older clients will send only the old field, while newer clients will populate both the old and new fields. The server side will need to implement logic to handle this situation. Before: record Request { string a; int b; } After: record Request { string a; int b; boolean c = true; } G: Renaming a field This is NOT safe. Avro has no way of knowing that field b in the writer (client’s) schema and field c in the reader (server’s) schema refer to the same field. Schema resolution on the server side will ignore the unkown field b and throw an error because the field c is not present. Before: record Request { string a; int b; } After: record Request { string a; int c; } H: Removing a field No action required. However, keep in mind that the value will be ignored when old clients include it in the request. Before: record Request { string a; int b; } After: record Request { string a; } Modifying the Response I: Adding a new non-optional field In this case, the old clients will ignore the value of the new field, so this is a compatible change. Before: record Response { string a; int b; } After: record Response { string a; int b; boolean c; } J: Adding a new optional field This is just a special case of the previous scenario. K: Adding a new item to a union In this scenario, older clients will fail when the server sets the field to a value with the new type. The safest solution would be to add a default value to the existing field and add a new field. Before: record Response { union {int, string} a; } After: record Response { union {int, string} a = 0; union {int, string, boolean} b; } L: Removing item from a union No action will be required in this case. Before: record Response { union {int, string, boolean} a; } After: record Response { union {int, string} a; } M: Replacing item from a union As long as the value of the union field belongs to one of the previous version’s types, older clients should be able to accept the response as valid. Thus, we would need to follow the same approach as above when Adding a new item to a union. Before: record Response { union {int, string} a; } After: record Response { union {int, boolean} a; } In this example, as long as the server only sends int values, we’re OK. N: Changing the type of an existing field We should add a default value to the existing field and add a new field with the new type. Before: record Response { string a; int b; } After: record Response { string a; int b = 123; boolean c; } O: Renaming a field This is NOT safe. Avro has no way of knowing that field b in the reader (client’s) schema and field c in the writer (server’s) schema refer to the same field. Schema resolution on the client side will ignore the unknown field c and throw an error because the field b is not present. Before: record Response { string a; int b; } After: record Response { string a; int c; } P: Removing a field This evolution should never happen since we would lose backward compatibility. Nonetheless, it would work only under the special case that the old response has a default value for the field that we want to delete, where this operation would be feasible by removing the field in the new version of the server response. Before: record Response { string a; int b = 123; } After: record Response { string a; }"
    } ,    
    {
      "title": "Generating sources from Avro",
      "url": "/mu-scala/guides/generate-sources-from-avro",
      "content": "Generating sources from Avro Getting started First add the sbt plugin in project/plugins.sbt: addSbtPlugin(\"io.higherkindness\" % \"sbt-mu-srcgen\" % \"0.31.1\") And enable the plugin on the appropriate project(s): enablePlugins(SrcGenPlugin) Once the plugin is enabled, you can configure it by adding a few lines to build.sbt: import higherkindness.mu.rpc.srcgen.Model._ // Look for Avro IDL files muSrcGenIdlType := IdlType.Avro Suppose you want to generate Scala code for a gRPC service based on the following Avro IDL file, src/main/resources/hello.avdl: @namespace(\"foo\") protocol AvroGreeter { record HelloRequest { string arg1; union { null, string } arg2; array&lt;string&gt; arg3; } record HelloResponse { string arg1; union { null, string } arg2; array&lt;string&gt; arg3; } foo.HelloResponse sayHelloAvro(foo.HelloRequest arg); } NOTE: please be aware that mu-scala restricts Avro RPC method arguments to a single record type and only permits records as return types; for more context, see the source generation reference. You can run the source generator directly: sbt muSrcGen or as part of compilation: sbt compile Once the source generator has run, there should be a generated Scala file at target/scala-3.1.2/src_managed/main/foo/AvroGreeter.scala. It will look like this (tidied up and simplified for readability): package foo final case class HelloRequest( arg1: String, arg2: Option[String], arg3: Seq[String] ) final case class HelloResponse( arg1: String, arg2: Option[String], arg3: Seq[String] ) trait AvroGreeter[F[_]] { def sayHelloAvro(arg: HelloRequest): F[HelloResponse] } object AvroGreeter { // ... lots of generated code } It’s also possible to generate Scala code from .avpr (JSON) files. Suppose you delete src/main/resources/hello.avdl and replace it with src/main/resources/hello.avpr: { \"namespace\" : \"foo\", \"protocol\" : \"AvroGreeter\", \"types\" : [ { \"name\" : \"HelloRequest\", \"type\" : \"record\", \"fields\" : [ { \"name\" : \"arg1\", \"type\" : \"string\" }, { \"name\" : \"arg2\", \"type\" : [ \"null\", \"string\" ] }, { \"name\" : \"arg3\", \"type\" : { \"type\" : \"array\", \"items\" : \"string\" } } ] }, { \"name\" : \"HelloResponse\", \"type\" : \"record\", \"fields\" : [ { \"name\" : \"arg1\", \"type\" : \"string\" }, { \"name\" : \"arg2\", \"type\" : [ \"null\", \"string\" ] }, { \"name\" : \"arg3\", \"type\" : { \"type\" : \"array\", \"items\" : \"string\" } } ] } ], \"messages\" : { \"sayHelloAvro\" : { \"request\" : [ { \"name\" : \"arg\", \"type\" : \"HelloRequest\" } ], \"response\" : \"HelloResponse\" } } } If you run sbt clean muSrcGen, you should end up with exactly the same generated Scala file as before. Avro code generation details This section explains the different Scala structures that are generated from Avro IDL. To achieve this generation Mu’s source generator uses avrohugger behind the scenes. Avro Protocols Let’s start from the beginning, everything in Avro IDL should be declared inside a protocol. The name of that protocol will be the name of our Scala file. protocol People { ... } muSrcGen =&gt; People.scala Furthermore, the protocol can have a namespace which will be our Scala package: @namespace(\"example.protocol\") protocol People { ... } muSrcGen =&gt; example/protocol/People.scala Messages In Avro IDL, the messages are declared with the keyword record and contain fields. The record will be translated to a case class with corresponding fields: record Person { string name; int age; boolean crossfitter; } muSrcGen =&gt; case class Person(name: String, age: Int, crossfitter: Boolean) Enums Avro supports enums too and they are translated to a Scala sealed trait + case objects: enum Errors { NotFound, Duplicated, None } muSrcGen =&gt; sealed trait Errors object Errors { @AvroSortPriority(0) case object NotFound extends Errors @AvroSortPriority(1) case object Duplicated extends Errors @AvroSortPriority(2) case object None extends Errors } Unions Unions are a complex Avro type for fields inside records. As its name suggest, it represents a type composed by another types. Depending on the types composing the union, Mu will interpret it on different ways: Optional fields When we add a null to a union expression, we’ll get a Scala Option of the other type declared along the null: record PeopleRequest { union {null, string} name; } muSrcGen =&gt; case class PeopleRequest(name: Option[String]) Eithers When we join two non-null types on a union we’ll get an Scala Either with the same types order: record PeopleResponse { union { Errors, Person } result; } muSrcGen =&gt; case class PeopleResponse(result: Either[Errors.Value, Person]) Scala union types And finally, when we have three or more non-null types on a single union, a TaggedUnion will be used. This is a wrapper around a Scala 3 union type, defined by Mu. record PeopleResponse { union{ string, int, Errors } result; } muSrcGen =&gt; case class PeopleResponse(result: TaggedUnion3[String, Int, Errors]) Services When we declare a method or endpoint inside a protocol this will be converted to a trait to define a Mu service. If we want to keep our models separate from our service definitions, Avro allows us to import other Avro files and use their records: protocol PeopleService { import idl \"People.avdl\"; //Under the same folder example.protocol.PeopleResponse getPerson(example.protocol.PeopleRequest request); } muSrcGen =&gt; trait PeopleService[F[_]] { def getPerson(request: example.protocol.PeopleRequest): F[example.protocol.PeopleResponse] } Also, an endpoint can be declared without params or not returning anything. Mu will use its Empty type to cover these cases: protocol PeopleService { void insertPerson(); } muSrcGen =&gt; trait PeopleService[F[_]] { def insertPerson(arg: Empty.type): F[Empty.type] } For a full understanding of the Avro syntax we recommend you to take a look to the Avro Official site where you can find all the Avro supported types and some interesting resources."
    } ,    
    {
      "title": "RPC service definition with Avro",
      "url": "/mu-scala/tutorials/service-definition/avro",
      "content": "Tutorial: RPC service definition with Avro gRPC supports Protocol Buffers by default for serialization of requests and responses, but it also allows you to use other serialization mechanisms, including Avro. This tutorial will show you how to generate a Mu RPC service definition from an Avro IDL file. Then a follow-up tutorial will guide you through using this service definition to create a fully working gRPC server or client. This tutorial is aimed at developers who: are new to Mu-Scala have some understanding of Avro and .avdl (Avro IDL) syntax have read the Getting Started guide This document will focus on Avro. If you would like to use gRPC with Protobuf, see the RPC service definition with Protobuf tutorial. Create a new Mu project As described in the Getting Started guide, we recommend you use the Mu-Scala giter8 template to create a new skeleton project. This will install and configure the mu-srcgen sbt plugin, which we will need to generate Scala code from an Avro .avdl file. When you create the project using sbt new, make sure to set create_sample_code to no. That way you can start with an empty project, and gradually fill in the implementation as you follow the tutorial. You should also set use_protobuf to no, and use_avro to yes. This will ensure the sbt project is correctly configured to generate code from Avro IDL files. Write the IDL file We’re going to start by writing a .avdl file containing a couple of messages. These messages will be used as the request and response types for a gRPC endpoint later. Copy the following Avro IDL and save it as protocol/src/main/resources/avro/greeter.avdl: @namespace(\"mu.examples.avro\") protocol Greeter { record HelloRequest { string name; } record HelloResponse { string greeting; boolean happy; } } Generate Scala code Now we have a .avdl file, we can generate Scala code from it. Start sbt and run the muSrcGen task. This will discover the .avdl file, parse it and generate corresponding Scala code. Let’s have a look at the code that Mu-Scala has generated. Open the file protocol/target/scala-2.13/src_managed/main/mu/examples/avro/Greeter.scala in your editor of choice. It should look something like this: package mu.examples.avro final case class HelloRequest(name: String) final case class HelloResponse(greeting: String, happy: Boolean) A few things to note: Mu-Scala has generated one case class for each Avro record The package name matches the namespace specified in the .avdl file Add an RPC service We now have some model classes to represent our RPC request and response, but we don’t have any RPC endpoints. Let’s fix that by adding a method to the Avro protocol. Add the following line to greeter.avdl to define an RPC endpoint: HelloResponse SayHello(HelloRequest request); Make sure that you add the line inside the protocol block, before the closing curly brace. Regenerate the code If you run the muSrcGen sbt task again, and inspect the protocol/target/scala-2.13/src_managed/main/mu/examples/avro/Greeter.scala file again, it should look something like this: package mu.examples.avro final case class HelloRequest(name: String) final case class HelloResponse(greeting: String, happy: Boolean) trait Greeter[F[_]] { def SayHello(request: mu.examples.avro.HelloRequest): F[mu.examples.avro.HelloResponse] } object Greeter { // ... lots of generated code } Now that our .avdl file has at least one method, we have an RPC service definition, so a corresponding trait has been added to the generated code. There’s quite a lot going on there, so let’s unpack it a bit. The trait is called Greeter, which matches the protocol name in the .avdl file. The trait contains a method for each endpoint in the service. Mu-Scala uses “tagless final” encoding: the trait has a higher-kinded type parameter F[_] and all methods return their result wrapped in F[...]. As we’ll see in a later tutorial, F[_] becomes an IO monad such as cats-effect IO when we implement a gRPC server or client. For details on how to customise this generated code using sbt settings, take a look at the source generation reference. Next steps To find out how to turn this service definition into a working gRPC client or server, continue to the gRPC server and client tutorial."
    } ,    
    {
      "title": "Compression",
      "url": "/mu-scala/guides/compression",
      "content": "Compression Mu supports compression of RPC requests and responses. We can enable this compression either on the server or the client side, or both. Mu supports Gzip as the compression format. Server side The server will automatically handle compressed requests from clients, decompressing them appropriately. To make the server compress its responses, set the muSrcGenCompressionType sbt setting to GzipGen This will configure sbt-mu-srcgen to enable compression in the code it generates. Client side The client will automatically handle compressed responses from servers, decompressing them appropriately. To make the client compress its requests, you need to add the appropriate “call option” when constructing the client. Here is an example of a client with request compression enabled. import cats.effect.* import higherkindness.mu.rpc.* import io.grpc.CallOptions import mu.examples.protobuf.greeter.* object CompressionExampleClient { val channelFor: ChannelFor = ChannelForAddress(\"localhost\", 12345) def clientResource[F[_]: Async]: Resource[F, Greeter[F]] = Greeter.client[F](channelFor, options = CallOptions.DEFAULT.withCompression(\"gzip\")) } Technical details To be strictly accurate, when you enable compression on the client or server side, the requests and responses are not compressed, but the messages inside them are. For example, if you enable compression on the client side, the client will compress the message when constructing a request. It will set the compression flag on the message to indicate that it is compressed, and it will set the grpc-encoding: gzip request header so that the server knows how to decompress the message."
    } ,    
    {
      "title": "Deploying a Mu service",
      "url": "/mu-scala/tutorials/deployment",
      "content": "Tutorial: Deploying a Mu service We don’t have documentation for this yet, but you may find this article useful: Mu in the cloud. It goes into significant detail, explaining how to deploy an example Mu application to Kubernetes in Google Cloud Platform. All of the code for that article is also available on GitHub for reference."
    } ,    
    {
      "title": "Distributed Tracing",
      "url": "/mu-scala/guides/distributed-tracing",
      "content": "Distributed Tracing Mu provides an integration with Natchez to enable distributed tracing of gRPC calls. Specifically, the integration provides the following features. Client For every RPC call, the client will create a child span with the fully qualified name of the RPC method being called (e.g. com.foo.Greeter/SayHello) It will automatically add all necessary trace-related headers to RPC requests. Server The server will attempt to extract trace-related information from the request headers. It will create a span using the same naming convention as the client. If the relevant headers were present, it will continue the trace that was started upstream, creating a child span. Otherwise, it will create a root span, i.e. a new trace. How to use Please, be sure you’ve checked the Accessing metadata on services first. Let’s look at how to enable tracing on the server side first. Server side We’ll assume the following service definition: case class HelloRequest(name: String) case class HelloResponse(greeting: String, happy: Boolean) trait Greeter[F[_]] { def SayHello(req: HelloRequest): F[HelloResponse] } and an implementation of that definition: import mu.examples.protobuf.greeter.* import cats.Applicative import cats.syntax.applicative.* class MyAmazingGreeter[F[_]: Applicative] extends Greeter[F] { def SayHello(req: HelloRequest): F[HelloResponse] = HelloResponse(s\"Hello, ${req.name}!\", happy = true).pure[F] } To use this service with tracing enabled, you need to call the Greeter.bindContextService[F, Span[F]] method instead of the usual Greeter.bindService[F]. That requires an instance of ServerContext[F, Span[F]], which is available in the higherkindness.mu.rpc.internal.tracing.implicits object: import higherkindness.mu.rpc.internal.context.ServerContext import natchez.{EntryPoint, Span} implicit def serverContext[F[_]](implicit entrypoint: EntryPoint[F]): ServerContext[F, Span[F]] So, to trace our service, we need to call to Greeter.bindContextService[F, Span[F]] with the import higherkindness.mu.rpc.internal.tracing.implicits.* in the scope and providing a Natchez EntryPoint implicitly. EntryPoint EntryPoint[F[_]], as the name suggests, is the “entrypoint” into the Natchez API. It’s what allows Mu to do things like create root spans. How you create an EntryPoint will depend on what tracing implementation you want to use. For example, if you use natchez-jaeger, you might create a Resource of an EntryPoint like this: import cats.effect.{Sync, Resource} import natchez.EntryPoint import natchez.jaeger.Jaeger import io.jaegertracing.Configuration.SamplerConfiguration import io.jaegertracing.Configuration.ReporterConfiguration def entryPoint[F[_]: Sync]: Resource[F, EntryPoint[F]] = { Jaeger.entryPoint[F](\"my-Mu-service\") { c =&gt; Sync[F].delay { c.withSampler(SamplerConfiguration.fromEnv) .withReporter(ReporterConfiguration.fromEnv) .getTracer } } } Kleisli When you instantiate your Greeter implementation, you need to set its type parameter to Kleisli[F, Span[F], *]. (Note: we are using kind-projector syntax here, but you don’t have to.) Intuitively, this creates a service which, given the current span as input, returns a result inside the F effect. Luckily, there are instances of most of the cats-effect type classes for Kleisli, all the way down to Async. So you should be able to substitute Greeter[Kleisli[F, Span[F], *]] for Greeter[F] without requiring any changes to your service implementation code. Using bindContextService Putting all this together, your server setup code will look something like this: import cats.effect.* import cats.data.Kleisli import higherkindness.mu.rpc.server.* import natchez.Span object TracingServer extends IOApp { import higherkindness.mu.rpc.internal.tracing.implicits.* given Greeter[Kleisli[IO, Span[IO], *]] = new MyAmazingGreeter[Kleisli[IO, Span[IO], *]] def run(args: List[String]): IO[ExitCode] = entryPoint[IO] .flatMap { implicit ep =&gt; Greeter.bindContextService[IO, Span[IO]] } .flatMap { serviceDef =&gt; GrpcServer.defaultServer[IO](8080, List(AddService(serviceDef))) }.useForever } Tracing your service code If you wish, you can make use of the Natchez Trace typeclass to create child spans: import natchez.Trace import cats.Monad import cats.syntax.all.* class MyTracingService[F[_]: Monad: Trace] extends Greeter[F] { def SayHello(req: HelloRequest): F[HelloResponse] = for { _ &lt;- Trace[F].span(\"look stuff up in the database\"){ Monad[F].unit } _ &lt;- Trace[F].span(\"do some stuff with Redis\"){ Monad[F].unit } _ &lt;- Trace[F].span(\"make an HTTP call\"){ Monad[F].unit } } yield HelloResponse(s\"Hi, ${req.name}!\") } Client side To obtain a tracing client, use Greeter.contextClient[F, Span[F]] instead of Greeter.client. This returns a Greeter[Kleisli[F, Span[F], *]], i.e. a client which takes the current span as input and returns a response inside the F effect. Similar to the server side, there’s a ClientContext[F, Span[F]] instance available in the higherkindness.mu.rpc.internal.tracing.implicits object: import cats.effect.Async import higherkindness.mu.rpc.internal.context.ClientContext import natchez.Span implicit def clientContext[F[_]: Async]: ClientContext[F, Span[F]] For example: import higherkindness.mu.rpc.* object TracingClientApp extends IOApp { import higherkindness.mu.rpc.internal.tracing.implicits.* val channelFor: ChannelFor = ChannelForAddress(\"localhost\", 8080) val clientRes: Resource[IO, Greeter[Kleisli[IO, Span[IO], *]]] = Greeter.contextClient[IO, Span[IO]](channelFor) def run(args: List[String]): IO[ExitCode] = entryPoint[IO].use { ep =&gt; ep.root(\"this is the root span\").use { currentSpan =&gt; clientRes.use { client =&gt; val kleisli = client.SayHello(HelloRequest(\"Chris\")) for { resp &lt;- kleisli.run(currentSpan) _ &lt;- IO(println(s\"Response: $resp\")) } yield (ExitCode.Success) } } } } Working example To see a full working example of distributed tracing across multiple Mu services, take a look at this project in the mu-scala-examples repo: higherkindness/mu-scala-examples. The README explains how to run the example and inspect the resulting traces."
    } ,    
    {
      "title": "Further reading",
      "url": "/mu-scala/reference/further-reading",
      "content": "Useful links Higherkindness RPC gRPC Avro Protocol Buffers Docs FS2 Docs gRPC Java API Metrifier HTTP/2 Comparing HTTP and RPC This is not specifically about Mu. Very often our microservices architectures are based on HTTP with JSON serialization, but perhaps it is not the best glue to connect them, and RPC services might be a better fit. Metrifier is a project where we compare, in different bounded ecosystems, HTTP and RPC. We found that RPC is usually faster than HTTP + JSON. If you’re interested in learning more, we encourage you to take a look at the documentation. Next Steps If you want to dive deeper into Mu, we have a complete example in the examples repo, which is based on the Route Guide Demo originally shared by the gRPC Java Project."
    } ,    
    {
      "title": "Getting Started",
      "url": "/mu-scala/getting-started",
      "content": "Getting Started The easiest way to get started is to use our giter8 template to start a new project: sbt new higherkindness/mu-scala.g8 You can customise the template using a few parameters: The template will generate an sbt project with 3 modules: the protocol module, for generating source code from Avro/Protobuf IDL files the server module, for a gRPC server the client module, for a gRPC client Template parameters There are a few important parameters to note. create_sample_code If you set the create_sample_code parameter to yes (the default value), the project will include sample code demonstrating how to build a gRPC server and client with Mu: the protocol module will contain a “hello world” Avro/Protobuf IDL file the client module will contain a working implementation of a gRPC client the server module will contain a working implementation of a gRPC server, as well as a unit test If you set create_sample_code to no, the three modules will still be created, but they will be empty. use_protobuf and use_avro You should set exactly one of these to yes, and the other to no. Depending on these parameters, the example IDL file created in the protocol module will be either a .proto or a .avdl file. Try it out If you chose to create sample code, you can see everything working: Start the server with sbt server/run In another terminal window, run the client with sbt client/run and enter your name when prompted You should see something like this: You can also run the unit test with sbt server/test. Next steps Learn more about Mu-Scala concepts by following a tutorial. The RPC service definition with Protobuf tutorial, or RPC service definition with Avro if you prefer Avro, is a good place to start."
    } ,    
    {
      "title": "gRPC server and client",
      "url": "/mu-scala/tutorials/grpc-server-client",
      "content": "Tutorial: gRPC server and client This tutorial will show you how to implement a working gRPC server and client based on a Mu service defintion. This tutorial is aimed at developers who: are new to Mu-Scala have some understanding of cats-effect have read the Getting Started guide have followed either the RPC service definition with Protobuf or RPC service definition with Avro tutorial Mu supports both Protobuf and Avro. For the purposes of this tutorial we will assume you are using Protobuf, but it’s possible to follow the tutorial even if you are using Avro. Service definition If you have followed one of the previous tutorials, you should already have a service definition that looks like this: trait Greeter[F[_]] { def SayHello(req: HelloRequest): F[HelloResponse] } object Greeter { // ... lots of generated code } Implement the server This is the interesting part: writing the business logic for your service. We do this by implementing the Greeter trait. Let’s make a Greeter that says “hello” in a happy voice: import cats.Applicative import cats.syntax.applicative.* import mu.examples.protobuf.greeter.* class HappyGreeter[F[_]: Applicative] extends Greeter[F] { def SayHello(req: HelloRequest): F[HelloResponse] = HelloResponse(s\"Hello, ${req.name}!\", happy = true).pure[F] } Note that in this implementation we aren’t performing any effects, so we don’t care what F[_] is as long as we can lift a pure value into it. Server entrypoint Now we have a Greeter implementation, let’s expose it as a gRPC server. We’re going to use cats-effect IO as our concrete IO monad, and we’ll make use IOApp from cats-effect. import cats.effect.{IO, IOApp, ExitCode, Resource} import mu.examples.protobuf.greeter.Greeter import higherkindness.mu.rpc.server.{GrpcServer, AddService} object Server extends IOApp { given Greeter[IO] = new HappyGreeter[IO] // 1 def run(args: List[String]): IO[ExitCode] = (for { serviceDef &lt;- Greeter.bindService[IO] // 2 server &lt;- Resource.eval(GrpcServer.default[IO](12345, List(AddService(serviceDef)))) // 3 _ &lt;- GrpcServer.serverResource[IO](server) // 4 } yield ()).useForever } Let’s go through this line by line. First we instantiate our HappyGreeter, concretized to IO, and make it available implicitly for use by Greeter.bindService. Next we call Greeter.bindService. This is an auto-generated helper method that converts our Greeter service into a gRPC “service definition”, returning IO[io.grpc.ServerServiceDefinition]. Each Scala method in the service will become a gRPC method of the same name. We build a description of the whole gRPC server by calling GrpcServer.default. We tell it the port we want to run on (12345), and the list of services we want it to expose. The method is called default because we want to use gRPC’s default HTTP transport layer. Finally we can call GrpcServer.serverResource, passing it our server description. This actually starts the server. If you copy the above code into a .scala file in the server module of your project, you should be able to start a server using sbt server/run. Client Let’s see how to make a client to communicate with the server. Here is a tiny demo that makes a request to the SayHello endpoint and prints out the reply to the console. import cats.effect.{IO, IOApp, Resource, ExitCode} import mu.examples.protobuf.greeter.{Greeter, HelloRequest} import higherkindness.mu.rpc.* object ClientDemo extends IOApp { val channelFor: ChannelFor = ChannelForAddress(\"localhost\", 12345) // 1 val clientResource: Resource[IO, Greeter[IO]] = Greeter.client[IO](channelFor) // 2 def run(args: List[String]): IO[ExitCode] = for { response &lt;- clientResource.use(c =&gt; c.SayHello(HelloRequest(name = \"Chris\"))) // 3 serverMood = if (response.happy) \"happy\" else \"unhappy\" _ &lt;- IO(println(s\"The $serverMood server says '${response.greeting}'\")) } yield ExitCode.Success } Again we’ll go through this line by line. We create a channel, which tells the client how to connect to the server. We call Greeter.client, another auto-generated helper method. This returns a cats-effect Resource, which will take care of safely allocating and cleaning up resources every time we want to use a client. We use the resource, using the resulting client to send a request to the SayHello endpoint and get back a response. If you copy the above code into a .scala file in the client module of your project, and your server is still running, you should be able to see the client in action using sbt client/run. [info] running com.example.ClientDemo The happy server says 'Hello, Chris!' [success] Total time: 1 s, completed 5 Mar 2020, 15:49:03 Next steps If you want to write tests for your RPC service, take a look at the Testing an RPC service tutorial."
    } ,    
    {
      "title": "gRPC Streaming",
      "url": "/mu-scala/guides/grpc-streaming",
      "content": "gRPC Streaming In the tutorials, we only defined gRPC services with so-called “unary” endpoints. This is an endpoint that does not involve streaming. The client sends a single request and receives a single response. gRPC also defines the following kinds of streaming, all of which are supported by Mu. Server streaming RPC: similar to the unary service, but in this case the server will send back a stream of responses for a client request. Client streaming RPC: in this case is the client which sends a stream of requests. The server will respond with a single response. Bidirectional streaming RPC: a mix of server and client streaming as both sides will be sending a stream of data. Protobuf Mu only officially supports streaming for Protobuf, not Avro. This is because Avro does not (yet) have support for streaming RPC endpoints in its protocol specification. The relevant Avro issue is AVRO-406. Stream implementation Mu uses FS2 Stream for streaming of RPC requests and responses. Service definition with streaming endpoints Let’s see what a Mu RPC service definition looks like when we introduce streaming endpoints. Here is an example .proto file: syntax = \"proto3\"; package mu.examples.protobuf.greeter; message HelloRequest { string name = 1; } message HelloResponse { string greeting = 1; } service StreamingGreeter { rpc LotsOfHellos (stream HelloRequest) returns (HelloResponse); rpc LotsOfReplies (HelloRequest) returns (stream HelloResponse); rpc BidirectionalHello (stream HelloRequest) returns (stream HelloResponse); } The service defines 3 RPC endpoints: LotsOfHellos is client-streaming LotsOfReplies is server-streaming BidirectionalHello is bidirectional streaming Service definition in Scala If we use the sbt-mu-srcgen plugin to generate Scala code, it will output a service definition that looks like this (cleaned up for readability): package mu.examples.protobuf.greeter.streaming trait StreamingGreeter[F[_]] { def LotsOfHellos(req: Stream[F, HelloRequest]): F[HelloResponse] def LotsOfReplies(req: HelloRequest): F[Stream[F, HelloResponse]] def BidirectionalHello(req: Stream[F, HelloRequest]): F[Stream[F, HelloResponse]] } object StreamingGreeter { // ... lots of generated code } Service implementation example An implementation of this service on the server side might look something like this: import mu.examples.protobuf.greeter.streaming.* import cats.effect.Concurrent import cats.syntax.all.* import fs2.Stream class MyStreamingGreeter[F[_]: Concurrent] extends StreamingGreeter[F] { def LotsOfHellos(reqStream: Stream[F, HelloRequest]): F[HelloResponse] = reqStream.compile.toList.map { requests =&gt; val names = requests.map(_.name).mkString(\" and \") HelloResponse(s\"Hello, $names\") } def LotsOfReplies(req: HelloRequest): F[Stream[F, HelloResponse]] = Stream( HelloResponse(s\"Hello, ${req.name}\"), HelloResponse(s\"Hello again, ${req.name}\") ).covary[F].pure[F] def BidirectionalHello(reqStream: Stream[F, HelloRequest]): F[Stream[F, HelloResponse]] = reqStream.map(req =&gt; HelloResponse(s\"Hello, ${req.name}\")).pure[F] }"
    } ,    
    {
      "title": "Backward/Forward Data Evolution",
      "url": "/mu-scala/reference/schema-evolution",
      "content": "Backward/Forward Data Evolution This section is about how data flows through the network, and how are they encoded/decoded into/from bytes in both sides of the wire in a compatible way. Currently, Mu brings the ability to encode data in bytes based on Avro and Protocol buffers. In the next sections, we are going to pass through both serialization standards to see how to preserve both forward and backward compatibility in your system: Avro Protocol Buffers"
    } ,    
    {
      "title": "Reference",
      "url": "/mu-scala/reference",
      "content": "Reference This is a collection of reference material about Mu-Scala."
    } ,    
    {
      "title": "Generating sources from IDL",
      "url": "/mu-scala/guides/generate-sources-from-idl",
      "content": "Generate sources from IDL Mu can generate code from a number of different IDL formats: message classes, gRPC server and client from Protobuf .proto files (see Generating sources from Protocol Buffers for detailed instructions) message classes, gRPC server and client from Avro .avpr or .avdl files (see Generating sources from Avro) Plugin Installation Add the following line to project/plugins.sbt: addSbtPlugin(\"io.higherkindness\" % \"sbt-mu-srcgen\" % \"0.31.1\") And enable the plugin on the appropriate project(s): enablePlugins(SrcGenPlugin) How to use the plugin The plugin will automatically integrate its source generation into your compile process, so the sources are generated before compilation when you run the compile task. You can also run the sbt task manually. To generate code from Avro IDL files: sbt muSrcGen Or for Protobuf: sbt protocGenerate Import If you want to customize the plugin’s configuration, you will need to add this import at the top of your build.sbt: import higherkindness.mu.rpc.srcgen.Model._ Settings For an explanation of the plugin’s settings, see the source generation reference."
    } ,    
    {
      "title": "How-To Guides",
      "url": "/mu-scala/guides",
      "content": "How-To Guides These guides are aimed at developers who are already familiar with Mu-Scala. If you are new to Mu-Scala, we recommend you read the Getting Started guide and the tutorials. Each guide introduces a single feature of Mu-Scala and explains how to use it."
    } ,    
    {
      "title": "Tutorials",
      "url": "/mu-scala/tutorials",
      "content": "Tutorials These tutorials are aimed at beginners to Mu-Scala. We recommend you read them in roughly the order they appear in the navigation menu. Before starting the tutorials, we recommend you read the Getting Started guide. If you are already familiar with Mu-Scala, you may want to read about how to use its more advanced features in the How-To Guides."
    } ,    
    {
      "title": "Mu",
      "url": "/mu-scala/",
      "content": "Mu-Scala Mu is a suite of libraries and tools that help you build and maintain microservices and clients in a functional style. Getting Started If you’re new to Mu-Scala, check out the Getting Started guide and the tutorials. Features While you focus on implementing the business logic for your service, let Mu take care of the boilerplate and non-functional requirements, including: generation of model classes, service interfaces and clients from Avro, or Protobuf IDL files serialization of requests and responses into Avro/Protobuf building high-performance gRPC servers and clients handling of streaming requests and responses using FS2 Stream accessing metadata on services distributed tracing metrics reporting … and plenty more features on the way! Specifically, Mu helps you to build gRPC servers and clients based on either Avro or Protobuf protocol definitions. Scala versions Mu is available for Scala 2.13 and 3.x. However, Avro support for Scala 3 should be considered experimental because the Scala 3 version of Avro4s is not yet feature-complete. For example, fields with default values are not supported properly. Most code samples in this documentation site use Scala 3 syntax."
    } ,      
    {
      "title": "Metrics Reporting",
      "url": "/mu-scala/guides/metrics-reporting",
      "content": "Metrics Reporting Currently, Mu provides two different ways to report metrics about gRPC services: Prometheus and Dropwizard Metrics. The usage is quite similar for both. Mu exposes the following metrics, for both servers and clients: Active calls: number of in-flight messages Messages sent: number of requests sent by the client or responses sent by the server (distributed by service name and method name). Messages received: number of requests received by the server or responses received by the client (distributed by service name and method name). Timers for header calls, total calls, and also distributed by method types (unary, streaming, …) and statuses (ok, canceled, …). Monitor Server Calls In order to monitor the RPC calls on the server side we need two things: A MetricsOps implementation. MetricsOps is an algebra located in the mu-rpc-service module, which defines the necessary operations for reporting metrics. Mu provides two implementations, one for Prometheus and another one for Dropwizard but you can provide your own. A MetricsServerInterceptor. Mu provides an interceptor that receives a MetricsOps as an argument and collects server metrics. Let’s see how to register server metrics using Prometheus in the following fragment. import mu.examples.protobuf.greeter.* import cats.effect.{IO, Resource} import cats.effect.std.Dispatcher import higherkindness.mu.rpc.prometheus.PrometheusMetrics import higherkindness.mu.rpc.server.* import higherkindness.mu.rpc.server.interceptors.implicits.* import higherkindness.mu.rpc.server.metrics.MetricsServerInterceptor import io.prometheus.client.CollectorRegistry object InterceptingServerCalls { lazy val cr: CollectorRegistry = new CollectorRegistry() given Greeter[IO] = new ServiceHandler[IO] val server: Resource[IO, GrpcServer[IO]] = for { metricsOps &lt;- Resource.eval(PrometheusMetrics.build[IO](cr, \"server\")) service &lt;- Greeter.bindService[IO] disp &lt;- Dispatcher[IO] withMetrics = service.interceptWith(MetricsServerInterceptor(metricsOps, disp)) server &lt;- GrpcServer.defaultServer[IO](8080, List(AddService(withMetrics))) } yield server } Monitor Client Calls In this case, in order to intercept the client calls we need additional configuration settings (by using AddInterceptor): import mu.examples.protobuf.greeter.* import cats.effect.{IO, Resource} import cats.effect.std.Dispatcher import higherkindness.mu.rpc.* import higherkindness.mu.rpc.channel.* import higherkindness.mu.rpc.channel.metrics.MetricsChannelInterceptor import io.prometheus.client.CollectorRegistry object InterceptingClientCalls { lazy val cr: CollectorRegistry = new CollectorRegistry() val serviceClient: Resource[IO, Greeter[IO]] = for { metricsOps &lt;- Resource.eval(PrometheusMetrics.build[IO](cr, \"client\")) disp &lt;- Dispatcher[IO] serviceClient &lt;- Greeter.client[IO]( channelFor = ChannelForAddress(\"localhost\", 8080), channelConfigList = List(UsePlaintext(), AddInterceptor(MetricsChannelInterceptor(metricsOps, disp)))) } yield serviceClient } That is how we use Prometheus to monitor both gRPC ends. Dropwizard Metrics The usage the same as before, but in this case we need to create a Dropwizard backed MetricsOps: import cats.effect.IO import com.codahale.metrics.MetricRegistry import higherkindness.mu.rpc.dropwizard.DropWizardMetrics val registry: MetricRegistry = new MetricRegistry() val metricsOps = DropWizardMetrics[IO](registry) To check the metrics from our server or client, Dropwizard exposes it through JMX. You’ll need the following dependency: \"io.dropwizard.metrics\" % \"metrics-jmx\" % \"4.1.4\" And to associate a JMX reporter with the metrics registry on your project, val jmxReporter = com.codahale.metrics.jmx.JmxReporter.forRegistry(registry) jmxReporter.build().start() Further reading You can see a full example in the metrics integration with Mu blog post."
    } ,    
    {
      "title": "Modules and artifacts",
      "url": "/mu-scala/reference/modules-artifacts",
      "content": "Mu-Scala modules and artifacts Mu is divided into multiple artifacts, grouped by scope: Server: specifically for RPC servers Client: specifically for RPC clients Server/Client: used from other artifacts for both Server and Client. Test: useful to test Mu applications. All of these artifacts are published for both Scala 2.13 and 3.x, except where noted below. RPC Client/Server Artifact Name Scope Mandatory Description mu-rpc-service Server/Client Yes Mandatory to build gRPC services and clients. mu-rpc-fs2 Server/Client Yes Mandatory to define streaming operations with FS2 Streams. mu-rpc-server Server Yes Needed to attach RPC Services and spin-up an RPC Server. mu-rpc-client-netty Client Yes* Netty transport layer for the client. Mandatory if you need SSL/TLS support. mu-rpc-client-okhttp Client Yes* OkHttp transport layer for the client. An alternative to Netty. mu-rpc-netty-ssl Server/Client No Adds the io.netty:netty-tcnative-boringssl-static:jar dependency, aligned with the Netty version (if that’s the case) used in the mu-rpc build. See this section for more information. By adding this you wouldn’t need to figure the right version, mu-rpc gives you the right one. Yes*: on the client-side, you must choose either Netty or OkHttp as the transport layer. Metrics Artifact Name Scope Mandatory Description mu-rpc-prometheus Server/Client No Interceptors which can be used to monitor gRPC services using Prometheus. mu-rpc-dropwizard Server/Client No Interceptors which can be used to monitor gRPC services using Dropwizard metrics. Other Artifact Name Scope Mandatory Description mu-config Server/Client No Provides configuration helpers using pureconfig to load the application configuration values. Only available for Scala 2.13 because there is no Scala 3 build of pureconfig yet. mu-rpc-testing Test No Utilities to test out Mu applications. It provides the grpc-testing library as the transitive dependency. mu-rpc-client-cache Client No Provides an algebra for caching RPC clients. Build You can install any of these dependencies in your build as follows: // required for a protocol definition: libraryDependencies += \"io.higherkindness\" %% \"mu-rpc-service\" % \"0.31.1\" // required for a protocol definition with streaming operations: libraryDependencies += \"io.higherkindness\" %% \"mu-rpc-fs2\" % \"0.31.1\" // required for the RPC server libraryDependencies += \"io.higherkindness\" %% \"mu-rpc-server\" % \"0.31.1\" // required for the use of generated RPC clients, using either Netty or OkHttp as transport layer: libraryDependencies += \"io.higherkindness\" %% \"mu-rpc-client-netty\" % \"0.31.1\" // or: libraryDependencies += \"io.higherkindness\" %% \"mu-rpc-client-okhttp\" % \"0.31.1\" // optional - for easy RPC server/client configuration. libraryDependencies += \"io.higherkindness\" %% \"mu-config\" % \"0.31.1\" // optional - for RPC server/client metrics reporting, using Prometheus. libraryDependencies += \"io.higherkindness\" %% \"mu-rpc-prometheus\" % \"0.31.1\" // optional - for RPC server/client metrics reporting, using Dropwizard. libraryDependencies += \"io.higherkindness\" %% \"mu-rpc-dropwizard\" % \"0.31.1\" // optional - for communication between RPC server and client using SSL/TLS. libraryDependencies += \"io.higherkindness\" %% \"mu-rpc-netty-ssl\" % \"0.31.1\" // optional - to add caching support to RPC clients. libraryDependencies += \"io.higherkindness\" %% \"mu-rpc-client-cache\" % \"0.31.1\" // optional - for testing RPC services libraryDependencies += \"io.higherkindness\" %% \"mu-rpc-testing\" % \"0.31.1\" % Test sbt plugin To generate Scala code from IDL files (.proto, .avdl, etc.), you will need the sbt-mu-srcgen plugin: addSbtPlugin(\"io.higherkindness\" %% \"sbt-mu-srcgen\" % \"0.31.1\")"
    } ,      
    {
      "title": "Schema Evolution - Protobuf",
      "url": "/mu-scala/reference/schema-evolution/proto",
      "content": "Protocol Buffers - Schema Evolution Work in progress"
    } ,    
    {
      "title": "Generating sources from Protobuf",
      "url": "/mu-scala/guides/generate-sources-from-proto",
      "content": "Generating sources from Protocol Buffers Getting started First add the sbt plugin in project/plugins.sbt: addSbtPlugin(\"io.higherkindness\" % \"sbt-mu-srcgen\" % \"0.31.1\") And enable the plugin on the appropriate project(s): enablePlugins(SrcGenPlugin) Once the plugin is enabled, you can configure it by adding a few lines to build.sbt: import higherkindness.mu.rpc.srcgen.Model._ // Look for .proto files muSrcGenIdlType := IdlType.Proto Suppose you want to generate Scala code for a gRPC service based on the following Protobuf IDL file, src/main/resources/hello.proto: syntax = \"proto3\"; package foo; message HelloRequest { string arg1 = 1; string arg2 = 2; repeated string arg3 = 3; } message HelloResponse { string arg1 = 1; string arg2 = 2; repeated string arg3 = 3; } service ProtoGreeter { rpc SayHelloProto (HelloRequest) returns (HelloResponse); } You can run the source generator directly: sbt protocGenerate or as part of compilation: sbt compile Once the source generator has run, there should be some generated Scala file under target/scala-2.13/src_managed/main/foo/hello/. There will be a separate file for each message class, plus a file for the service definition. HelloRequest.scala will look roughly like this (tidied up and simplified for readability): package foo.hello final case class HelloRequest( arg1: String = \"\", arg2: String = \"\", arg3: Seq[String] = Seq.empty ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[HelloRequest] { // ... lots of generated code } Note how each field has a default value, in line with the Protobuf spec. The service definition in ProtoGreeter.scala will look something like this: trait ProtoGreeter[F[_]] { def SayHelloProto(req: HelloRequest): F[HelloResponse] } object ProtoGreeter { // ... lots of generated code } Custom types ScalaPB allows you to customise what types are used in the generated code. For example, if you have a string field in your Protobuf message that represents a date, you might want to model it in Scala using java.time.LocalDate. Take a look at the ScalaPB docs for details on how to achieve this using ScalaPB’s TypeMapper mechanism."
    } ,    
    {
      "title": "RPC service definition with Protobuf",
      "url": "/mu-scala/tutorials/service-definition/protobuf",
      "content": "Tutorial: RPC service definition with Protobuf This tutorial will show you how to generate a Mu RPC service definition from a Protocol Buffers protocol file. Then a follow-up tutorial will guide you through using this service definition to create a fully working gRPC server or client. This tutorial is aimed at developers who: are new to Mu-Scala have some understanding of Protobuf and .proto file syntax have read the Getting Started guide This document will focus on Protobuf. If you would like to use gRPC with Avro, see the RPC service definition with Avro tutorial. Create a new Mu project As described in the Getting Started guide, we recommend you use the Mu-Scala giter8 template to create a new skeleton project. This will install and configure the mu-srcgen sbt plugin, which we will need to generate Scala code from a Protobuf .proto file. When you create the project using sbt new, make sure to set create_sample_code to no. That way you can start with an empty project, and gradually fill in the implementation as you follow the tutorial. Write the Protobuf protocol We’re going to start by writing a .proto file containing a couple of messages. These messages will be used as the request and response types for a gRPC endpoint later. Copy the following Protobuf protocol and save it as protocol/src/main/resources/greeter.proto: syntax = \"proto3\"; package mu.examples.protobuf; message HelloRequest { string name = 1; } message HelloResponse { string greeting = 1; bool happy = 2; } Generate Scala code Now we have a .proto file, we can generate Scala code from it. Start sbt and run the compile task. This will trigger the sbt-mu-srcgen plugin to generate some Scala source files from the .proto file, and then those Scala files will be compiled. sbt:hello-mu-protobuf&gt; compile [info] Compiling 1 protobuf files to /Users/chris/code/hello-mu-protobuf/protocol/target/scala-2.13/src_managed/main [info] compiling 3 Scala sources to /Users/chris/code/hello-mu-protobuf/protocol/target/scala-2.13/classes ... [success] Total time: 2 s, completed 28 Apr 2022, 12:08:49 Let’s have a look at the code that was generated. Open the file protocol/target/scala-2.13/src_managed/main/mu/examples/protobuf/greeter/HelloRequest.scala in your editor of choice. It’s generated code, so it will look pretty ugly. Here’s a version of it tidied up a bit to make it more readable: package mu.examples.protobuf.greeter final case class HelloRequest( name: String = \"\", unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty ) extends scalapb.GeneratedMessage { // ... lots of generated code } A few things to note: Mu-Scala has generated one case class for each Protobuf message The package name is derived from the protobuf package declaration in the .proto file (mu.examples.protobuf) and the filename (greeter.proto) hello.proto The case class extends scalapb.GeneratedMessage. The sbt-mu-srcgen plugin delegates generation of code from .proto files to another plugin called ScalaPB. Add an RPC service We now have some model classes to represent our RPC request and response, but we don’t have any RPC endpoints. Let’s fix that by adding a service to the Protobuf protocol. Add the following lines at the end of hello.proto to define an RPC service with one endpoint: service Greeter { rpc SayHello (HelloRequest) returns (HelloResponse); } Regenerate the code If you run the compile sbt task again, and inspect the protocol/target/scala-2.13/src_managed/main/mu/examples/greeter/Greeter.scala file, it should look something like this: trait Greeter[F[_]] { def SayHello(req: HelloRequest): F[HelloResponse] } object Greeter { // ... lots of generated code } A trait has been added to the generated code, corresponding to the service we added to hello.proto. There’s quite a lot going on there, so let’s unpack it a bit. The trait is called Greeter, which matches the service name in the .proto file. The trait contains a method for each endpoint in the service. Mu-Scala uses “tagless final” encoding: the trait has a higher-kinded type parameter F[_] and all methods return their result wrapped in F[...]. As we’ll see in a later tutorial, F[_] becomes an IO monad such as cats-effect IO when we implement a gRPC server or client. There is also a companion object containing a load of useful helper methods for creating servers and clients. We’ll see how to make use of these helpers in the next tutorial. For details on how to customise this generated code using sbt settings, take a look at the source generation reference. Next steps To find out how to turn this service definition into a working gRPC client or server, continue to the gRPC server and client tutorial."
    } ,      
    {
      "title": "Source generation",
      "url": "/mu-scala/reference/source-generation",
      "content": "Source generation reference This is a reference page for the sbt-mu-srcgen sbt plugin, which generates Scala source code from Avro/Protobuf IDL files. Tasks The sbt task used to perform source generation depends on your IDL type: For Avro, use the sbt-mu-srcgen plugin’s muSrcGen task For Protobuf, use the sbt-protoc plugin’s protocGenerate task (sbt-mu-srcgen automatically adds the sbt-protoc plugin to your project) Alternatively you can just run the compile task, and the appropriate source generation task will be executed before compilation. Settings This section explains each of the sbt plugin’s settings. As a reminder, this plugin needs to be manually enabled for any module for which you want to generate code; you can do that by adding the following to your build.sbt: enablePlugins(SrcGenPlugin) muSrcGenIdlType The most important sbt setting is muSrcGenIdlType, which tells the plugin what kind of IDL files (Avro/Protobuf) to look for. muSrcGenIdlType := IdlType.Proto // or IdlType.Avro muSrcGenSerializationType Another important setting is muSrcGenSerializationType, which specifies how messages should be encoded on the wire. This should match the format you chose for the muSrcGenIdlType setting: For Protobuf, there is no need to configure this setting, as there is only one possible serialization type For Avro, choose either SerializationType.Avro or SerializationType.AvroWithSchema. If you choose Avro, it means your client and server must always use exactly the same version of the schema. If you choose AvroWithSchema, the writer schema will be included in every message sent, which introduces a bandwidth overhead but allows schema evolution. In other words, the server and client can use different versions of a schema, as long as they are compatible with each other. See the schema evolution section for more details on schema evolution. muSrcGenSerializationType := SerializationType.Protobuf // or SerializationType.Avro or SerializationType.AvroWithSchema Other basic settings Setting Description Default value muSrcGenSourceDirs The list of directories where your IDL files can be found.Note: all the directories configured as sources will be distributed in the resulting jar artifact preserving the same folder structure as in the source. Compile / resourceDirectory, typically src/main/resources/ muSrcGenIdlTargetDir The directory where all discovered IDL files will be copied in preparation for Scala code generation. The plugin will automatically copy the following to the target directory: * All the IDL files and directories in the directory specified by muSrcGenSourceDirs * All the IDL files extracted from the JAR files or sbt modules specified by muSrcGenJarNames (see the “Advanced settings” section below) Compile / resourceManaged, typically target/scala-2.13/resource_managed/main muSrcGenTargetDir The directory where the muSrcGen task will write the generated files. The files will be placed in subdirectories based on the namespaces declared in the IDL files. Compile / sourceManaged, typically target/scala-2.13/src_managed/main/ Note: The directories referenced in muSrcGenSourceDirs must exist. Target directories will be created upon generation. Advanced settings Setting Description Default value muSrcGenJarNames A list of JAR file or sbt module names where extra IDL files can be found. See the muSrcGenJarNames section section below for more details. Nil muSrcGenIdlExtension The extension of IDL files to extract from JAR files or sbt modules. * avdl if muSrcGenIdlType is avro * proto if muSrcGenIdlType is Proto muSrcGenCompressionType The compression type that will be used by generated RPC services. Set to higherkindness.mu.rpc.srcgen.Model.GzipGen for Gzip compression. higherkindness.mu.rpc.srcgen.Model.NoCompressionGen muSrcGenIdiomaticEndpoints Flag indicating if idiomatic gRPC endpoints should be used. If true, the service operations will be prefixed by the namespace. true muSrcGenProtocVersion Specifies the protoc version that ScalaPB should use when generating source files from proto files. None (let ScalaPB choose the protoc version) muSrcGenValidateProto Flag indicating if the plugin should generate validation methods based on rules and constraints defined in the specs. Only proto is supported at this moment. false muSrcGenJarNames You can use IDL files packaged into artifacts within your classpath, e.g. JAR files added to the classpath via libraryDependencies, or other sbt modules. muSrcGenJarNames can be very useful when you want to distribute your IDL files without binary code (to prevent binary conflicts in clients). The following example shows how to set up a dependency with another artifact or sbt module containing the IDL definitions (foo-domain): //... .settings( Seq( muSrcGenIdlType := IdlType.Avro, muSrcGenSerializationType := SerializationType.AvroWithSchema, muSrcGenJarNames := Seq(\"foo-domain\"), muSrcGenTargetDir := (Compile / sourceManaged).value / \"compiled_avro\", libraryDependencies ++= Seq( \"io.higherkindness\" %% \"mu-rpc-service\" % V.muRPC ) ) ) //... muSrcGenValidateProto The sbt-mu-srcgen supports the plugin scalapb-validate. This plugin generates validators for your models, using the base validators defined by the PGV protoc plugin As you probably guessed, this is only compatible with proto and the setting will be ignored when working with Avro files. To enable the validation methods generation, you need to set the setting muSrcGenValidateProto to true and import the PVG validators provided transitively by the scalapb-validate-core protobuf library: //... .settings( Seq( muSrcGenIdlType := IdlType.Proto, muSrcGenTargetDir := (Compile / sourceManaged).value / \"compiled_proto\", muSrcGenValidateProto := true, libraryDependencies ++= Seq( \"com.thesamet.scalapb\" %% \"scalapb-validate-core\" % scalapb.validate.compiler.BuildInfo.version % \"protobuf\", \"io.higherkindness\" %% \"mu-rpc-service\" % V.muRPC ) ) ) //... Implementation Notes: An Intentional Incompatibility with the Avro Standard In order to make it easier for users to evolve their schemas over time, sbt-mu-srcgen intentionally deviates from the Avro standard in one key way: it restricts RPC return types to record types (string sendUser(UserWithCountry user) is not permitted) as well as restricting the arguments of RPC messages to none or to a single record type (SendUserResponse sendUser(UserWithCountry user, RequestId id) is not permitted). If you attempt to write an Avro schema using primitive types instead of records (for example, something like this): @namespace(\"foo\") protocol UserV1 { string sendUser(string user); } the source generation command (i.e. muSrcGen) will fail with an error message explaining why the protocol was rejected. For example, the above schema would trigger the following message: [error] (avro-protocol / Compile / muSrcGen) One or more IDL files are invalid. Error details: [error] /path/to/the/invalid/file.avdl has the following errors: RPC method request parameter 'user' has non-record request type 'STRING', RPC method response parameter has non-record response type 'STRING' Additional Context To understand this potential issue with schema evolution, consider the following example, record SearchRequest { string query; } SearchResponse search(SearchRequest request); This schema can be evolved to add optional fields (e.g. ordering, filters, …) to the request. All the user has to do is just change the single record. The following API design, on the other hand, can’t be evolved because changing the query argument from a string to any other datatype would introduce backward incompatibility. SearchResponse search(string query); For this reason, we enforce that all requests and responses must be records. The reason for disallowing multiple request arguments, on the other hand, is that the gRPC spec does not support it. There is no obvious way to map multiple arguments in the Avro RPC definition to a single gRPC request."
    } ,    
    {
      "title": "SSL/TLS",
      "url": "/mu-scala/guides/ssl-tls",
      "content": "SSL/TLS Encryption From the gRPC authentication guide: gRPC has SSL/TLS integration and promotes the use of SSL/TLS to authenticate the server and encrypt all the data exchanged between the client and the server. Optional mechanisms are available for clients to provide certificates for mutual authentication. Mu allows you to encrypt the connection between the server and the client through SSL/TLS. The main goal of using SSL is to protect your sensitive information and to keep your data secure between servers and clients. Netty transport Mu allows you to choose the underlying transport layer you want to use for your gRPC servers and clients: For the server you can use Netty, or the default transport provided by the gRPC Java library. (In reality the default transport will also be Netty, unless you have written your own io.grpc.ServerProvider implementation and added it to the classpath.) For the client you can use Netty or OkHttp. However, SSL/TLS encryption in Mu is currently only supported for servers and clients that use the Netty transport. Requirements On the server and client side, we will need two files to configure the SslContext in gRPC: Server/Client certificate file: Small data files that digitally bind a cryptographic key to an organization’s details. This file could be generated or obtained from a third party. Server/Client private key file: The private key is a separate file that is used in the encryption of data sent between your server and the clients. All SSL certificates require a private key to work. Usage The first step to secure our Mu services is to add the library dependencies mu-rpc-netty-ssl and mu-rpc-client-netty in our build. For the second step, we have to move both server/client certificates and private keys to a place where they can be loaded at runtime, either from the filesystem or the classpath. However, these files contain secrets, so they should not be included in the project and committed to git. If we haven’t yet generated or obtained our own certificates, we can test using certificates found here. Server side Let’s see a piece of code where we will explain line by line how to build a gRPC server with SSL encryption enabled. We won’t cover the details of implementing the Greeter service or starting the gRPC server. You can find more information about these in the gRPC server and client tutorial. import java.io.File import java.security.cert.X509Certificate import cats.effect.{IO, Resource} import higherkindness.mu.rpc.server.netty.SetSslContext import higherkindness.mu.rpc.server.{AddService, GrpcConfig, GrpcServer} import io.grpc.internal.testing.TestUtils import io.grpc.netty.GrpcSslContexts import io.netty.handler.ssl.{ClientAuth, SslContext, SslProvider} object ServerExample { given Greeter[IO] = new ServiceHandler[IO] // Load the certicate and private key files. val serverCertFile: File = TestUtils.loadCert(\"server1.pem\") val serverPrivateKeyFile: File = TestUtils.loadCert(\"server1.key\") val serverTrustedCaCerts: Array[X509Certificate] = Array(TestUtils.loadX509Cert(\"ca.pem\")) // Build the SslContext, passing our server certificate, private key, and trusted certs. // Configure the server to use OpenSSL and require client authentication. val serverSslContext: SslContext = GrpcSslContexts .configure( GrpcSslContexts.forServer(serverCertFile, serverPrivateKeyFile), SslProvider.OPENSSL) .trustManager(serverTrustedCaCerts: _*) .clientAuth(ClientAuth.REQUIRE) .build() // Add the SslContext to the list of GrpConfigs. val grpcConfigs: Resource[IO, List[GrpcConfig]] = Greeter.bindService[IO] .map(AddService(_)) .map(c =&gt; List(SetSslContext(serverSslContext), c)) // Important: we have to create the server with Netty. // This is the only server transport that supports SSL encryption. val server: Resource[IO, GrpcServer[IO]] = grpcConfigs.evalMap(GrpcServer.netty[IO](8080, _)) } Client side Similarly, let’s see how to create a gRPC client with encryption and client authentication. import higherkindness.mu.rpc.ChannelForAddress import higherkindness.mu.rpc.channel.OverrideAuthority import higherkindness.mu.rpc.channel.netty.{NettyChannelInterpreter, NettyNegotiationType, NettySslContext} import io.grpc.netty.NegotiationType object ClientExample { // Load the certicate and private key files. val clientCertChainFile: File = TestUtils.loadCert(\"client.pem\") val clientPrivateKeyFile: File = TestUtils.loadCert(\"client.key\") val clientTrustedCaCerts: Array[X509Certificate] = Array(TestUtils.loadX509Cert(\"ca.pem\")) // We have to create the SslContext for the client, like we did for the server. val clientSslContext: SslContext = GrpcSslContexts.forClient .keyManager(clientCertChainFile, clientPrivateKeyFile) .trustManager(clientTrustedCaCerts: _*) .build() // Important: the channel interpreter must be NettyChannelInterpreter. // We configure the channel interpreter to enable TLS and to use the SSL context we built. val channelInterpreter: NettyChannelInterpreter = new NettyChannelInterpreter( ChannelForAddress(\"localhost\", 8080), List(OverrideAuthority(TestUtils.TEST_SERVER_HOST)), List( NettyNegotiationType(NegotiationType.TLS), NettySslContext(clientSslContext) ) ) val muRPCServiceClient: Resource[IO, Greeter[IO]] = Greeter.clientFromChannel[IO](IO(channelInterpreter.build)) } Further reading For more details, here you can check a full explanation and an example about securing communications."
    } ,    
    {
      "title": "Testing an RPC service",
      "url": "/mu-scala/tutorials/testing-rpc-service",
      "content": "Tutorial: Testing an RPC service This tutorial will show you how to write a unit test for an RPC service using an in-memory channel and client. This tutorial is aimed at developers who: are new to Mu-Scala have read the Getting Started guide have followed the gRPC server and client tutorial Mu supports both Protobuf and Avro. For the purposes of this tutorial we will assume you are using Protobuf, but it’s possible to follow the tutorial even if you are using Avro. Service definition Let’s use the following service definition. (For an explanation of how to create a service definition, check out the RPC service definition with Protobuf tutorial.) A client sends a HelloRequest containing a name, and the server responds with a greeting and an indication of whether it is feeling happy or not. case class HelloRequest(name: String) case class HelloResponse(greeting: String, happy: Boolean) trait Greeter[F[_]] { def SayHello(req: HelloRequest): F[HelloResponse] } Service implementation Here’s the implementation we want to test. import cats.Applicative import cats.syntax.applicative.* import mu.examples.protobuf.greeter.* class HappyGreeter[F[_]: Applicative] extends Greeter[F] { def SayHello(req: HelloRequest): F[HelloResponse] = HelloResponse(s\"Hello, ${req.name}!\", happy = true).pure[F] } We’re going to write a test to check that the service is always happy. We’ll use the MUnit testing library, with munit-cats-effect for smooth integration with cats-effect IO. mu-rpc-testing We’ll also make use of the mu-rpc-testing module. This contains some helpers for setting up an in-memory service for testing. libraryDependencies += \"io.higherkindness\" %% \"mu-rpc-testing\" % \"0.31.1\" % Test Create the service and client The test will instantiate a HappyGreeter, but instead of connecting it to a real gRPC server and exposing it over HTTP, we’ll connect it to an in-memory channel. We’ll also create a client and connect it to the same in-memory channel, so it can make requests to the service. import mu.examples.protobuf.greeter.Greeter import cats.effect.{IO, Resource} import higherkindness.mu.rpc.testing.servers.withServerChannel trait ServiceAndClient { given Greeter[IO] = new HappyGreeter[IO] /* * A cats-effect Resource that builds a gRPC server and client * connected to each other via an in-memory channel. */ val clientResource: Resource[IO, Greeter[IO]] = for { sc &lt;- withServerChannel(Greeter.bindService[IO]) clientRes &lt;- Greeter.clientFromChannel[IO](IO.pure(sc.channel)) } yield clientRes } The important part here is the use of withServerChannel. This is a helper method provided by the mu-rpc-testing module that connects the service to an in-memory channel so we don’t need to start a real gRPC server. Write the test Now we’re ready to write our test. With the service and client in place, the test consists of using the client to make a request and then asserting that the response matches what we expect. import mu.examples.protobuf.greeter.{HelloRequest, HelloResponse} import munit.CatsEffectSuite class ServiceSpec extends CatsEffectSuite with ServiceAndClient { test(\"service is happy\") { clientResource .use(client =&gt; client.SayHello(HelloRequest(\"somebody\"))) .map(_.happy) .assertEquals(true) } } Run the test Let’s see the test in action: sbt:hello-mu-protobuf&gt; tests/test mu.examples.protobuf.greeter.ServiceSpec: + service is happy 0.314s [info] Passed: Total 1, Failed 0, Errors 0, Passed 1 Bonus points: property-based test Since the HappyGreeter service is always happy, we could also write this as a property-based test with ScalaCheck to verify that the service’s happiness does not depend on the incoming request. import munit.ScalaCheckSuite import org.scalacheck.Gen import org.scalacheck.Prop.* class PropertyBasedServiceSpec extends CatsEffectSuite with ScalaCheckSuite with ServiceAndClient { val requestGen: Gen[HelloRequest] = Gen.alphaStr.map(HelloRequest(_)) val client = ResourceSuiteLocalFixture(\"client\", clientResource) override def munitFixtures: Seq[Fixture[_]] = List(client) property(\"server is always happy\") { val c = client() forAllNoShrink(requestGen) { request =&gt; val response: HelloResponse = c.SayHello(request).unsafeRunSync() response.happy :| \"response should be happy\" } } } Let’s run this test as well: sbt:hello-mu-protobuf&gt; tests/testOnly mu.examples.protobuf.greeter.PropertyBasedServiceSpec mu.examples.protobuf.greeter.PropertyBasedServiceSpec: + server is always happy 0.243s [info] Passed: Total 1, Failed 0, Errors 0, Passed 1"
    }    
  ];

  idx = lunr(function () {
    this.ref("title");
    this.field("content");

    docs.forEach(function (doc) {
      this.add(doc);
    }, this);
  });

  docs.forEach(function (doc) {
    docMap.set(doc.title, doc.url);
  });
}

// The onkeypress handler for search functionality
function searchOnKeyDown(e) {
  const keyCode = e.keyCode;
  const parent = e.target.parentElement;
  const isSearchBar = e.target.id === "search-bar";
  const isSearchResult = parent ? parent.id.startsWith("result-") : false;
  const isSearchBarOrResult = isSearchBar || isSearchResult;

  if (keyCode === 40 && isSearchBarOrResult) {
    // On 'down', try to navigate down the search results
    e.preventDefault();
    e.stopPropagation();
    selectDown(e);
  } else if (keyCode === 38 && isSearchBarOrResult) {
    // On 'up', try to navigate up the search results
    e.preventDefault();
    e.stopPropagation();
    selectUp(e);
  } else if (keyCode === 27 && isSearchBarOrResult) {
    // On 'ESC', close the search dropdown
    e.preventDefault();
    e.stopPropagation();
    closeDropdownSearch(e);
  }
}

// Search is only done on key-up so that the search terms are properly propagated
function searchOnKeyUp(e) {
  // Filter out up, down, esc keys
  const keyCode = e.keyCode;
  const cannotBe = [40, 38, 27];
  const isSearchBar = e.target.id === "search-bar";
  const keyIsNotWrong = !cannotBe.includes(keyCode);
  if (isSearchBar && keyIsNotWrong) {
    // Try to run a search
    runSearch(e);
  }
}

// Move the cursor up the search list
function selectUp(e) {
  if (e.target.parentElement.id.startsWith("result-")) {
    const index = parseInt(e.target.parentElement.id.substring(7));
    if (!isNaN(index) && (index > 0)) {
      const nextIndexStr = "result-" + (index - 1);
      const querySel = "li[id$='" + nextIndexStr + "'";
      const nextResult = document.querySelector(querySel);
      if (nextResult) {
        nextResult.firstChild.focus();
      }
    }
  }
}

// Move the cursor down the search list
function selectDown(e) {
  if (e.target.id === "search-bar") {
    const firstResult = document.querySelector("li[id$='result-0']");
    if (firstResult) {
      firstResult.firstChild.focus();
    }
  } else if (e.target.parentElement.id.startsWith("result-")) {
    const index = parseInt(e.target.parentElement.id.substring(7));
    if (!isNaN(index)) {
      const nextIndexStr = "result-" + (index + 1);
      const querySel = "li[id$='" + nextIndexStr + "'";
      const nextResult = document.querySelector(querySel);
      if (nextResult) {
        nextResult.firstChild.focus();
      }
    }
  }
}

// Search for whatever the user has typed so far
function runSearch(e) {
  if (e.target.value === "") {
    // On empty string, remove all search results
    // Otherwise this may show all results as everything is a "match"
    applySearchResults([]);
  } else {
    const tokens = e.target.value.split(" ");
    const moddedTokens = tokens.map(function (token) {
      // "*" + token + "*"
      return token;
    })
    const searchTerm = moddedTokens.join(" ");
    const searchResults = idx.search(searchTerm);
    const mapResults = searchResults.map(function (result) {
      const resultUrl = docMap.get(result.ref);
      return { name: result.ref, url: resultUrl };
    })

    applySearchResults(mapResults);
  }

}

// After a search, modify the search dropdown to contain the search results
function applySearchResults(results) {
  const dropdown = document.querySelector("div[id$='search-dropdown'] > .dropdown-content.show");
  if (dropdown) {
    //Remove each child
    while (dropdown.firstChild) {
      dropdown.removeChild(dropdown.firstChild);
    }

    //Add each result as an element in the list
    results.forEach(function (result, i) {
      const elem = document.createElement("li");
      elem.setAttribute("class", "dropdown-item");
      elem.setAttribute("id", "result-" + i);

      const elemLink = document.createElement("a");
      elemLink.setAttribute("title", result.name);
      elemLink.setAttribute("href", result.url);
      elemLink.setAttribute("class", "dropdown-item-link");

      const elemLinkText = document.createElement("span");
      elemLinkText.setAttribute("class", "dropdown-item-link-text");
      elemLinkText.innerHTML = result.name;

      elemLink.appendChild(elemLinkText);
      elem.appendChild(elemLink);
      dropdown.appendChild(elem);
    });
  }
}

// Close the dropdown if the user clicks (only) outside of it
function closeDropdownSearch(e) {
  // Check if where we're clicking is the search dropdown
  if (e.target.id !== "search-bar") {
    const dropdown = document.querySelector("div[id$='search-dropdown'] > .dropdown-content.show");
    if (dropdown) {
      dropdown.classList.remove("show");
      document.documentElement.removeEventListener("click", closeDropdownSearch);
    }
  }
}
